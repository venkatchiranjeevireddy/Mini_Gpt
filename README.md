# Mini_Gpt
A lightweight, multi-capability AI assistant built for Google Colab using fine-tuned LLaMA 2 models, image captioning, document QA, live web retrieval, and more. Fully optimized for low-resource environments with 4-bit quantized models.
# ğŸ§  Unified AI Assistant

A modular, intelligent AI assistant built using fine-tuned and pre-trained models from Hugging Face. This project brings together text, document, image, and audio understanding â€” all optimized to run efficiently in Google Colab.

---

## ğŸš€ Features

- **ğŸ’¬ Natural Chatting**  
  Conversational AI powered by a fine-tuned LLaMA2 model with LoRA adapters.

- **ğŸ“ Text Summarization**  
  Condense long documents using a summarizer fine-tuned on news datasets.

- **ğŸ§¾ Text Generation**  
  Instruction-following and creative writing using a LoRA-tuned decoder model.

- **ğŸ“„ Document Question Answering**  
  Upload PDFs, TXT, DOCX, or CSV files and ask questions locally using a retrieval-augmented pipeline (RAG).

- **ğŸŒ Live Web + Wikipedia Search**  
  Ask any real-world question and get results in real-time using SerpAPI and Wikipedia.

- **ğŸ–¼ï¸ Image Generation**  
  Generate images from text prompts using a pretrained Stable Diffusion model.

- **ğŸ–¼ï¸ Image Captioning**  
  Upload an image and automatically generate a relevant caption using BLIP.

- **ğŸ”Š Audio Chat Assistant**  
  Speak into the system and get intelligent replies. Combines Whisper (speech-to-text) and gTTS (text-to-speech).

---

## ğŸ§  Fine-Tuned Intelligence

This project isnâ€™t just a wrapper on pre-trained models â€” several components are **fine-tuned using Hugging Face datasets**, including:

- `yahma/alpaca-cleaned` for conversational instruction tuning
- `cnn_dailymail` for summarization
- `euclaise/writingprompts` for story/text generation

Training was done using:
- ğŸ§© **PEFT (LoRA)** for efficient fine-tuning
- âš™ï¸ `bitsandbytes` for 8-bit memory optimization
- ğŸ§  LLaMA2 models for chat/text understanding

All models are tested and runnable on **Google Colab**, even with limited GPU (T4/V100, 16 GB).

---

## ğŸ” API Keys Used

To enable web search and Hugging Face model downloads, youâ€™ll need:

- `SERP_API_KEY` â€” for Google search (via SerpAPI)
- `HUGGINGFACE_TOKEN` â€” for using Hugging Face models programmatically

Add them directly in the notebook or as environment variables.

---

## ğŸ How to Use

1. Open the desired `.ipynb` or `.py` file in Google Colab.
2. Install required dependencies with:
   ```bash
   pip install -r requirements.txt
